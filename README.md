# Offensive-language-Detection
Social media can be used to share posts, comments. It is used to keep in touch with friends, family, relatives.
But at the same time, some people may use offensive language, spread hatred, mock or insult somebody on the basis of race, caste, religion.
This project aims to identify this comments and predict their toxicity.


## How to use
Download the code and unzip the Comments Model file in the same folder. Open the identifythecomment.ipynb notebook and try out some comments.
The notebook can be opened in Google Colab as well as in Jupyter Notebook.

## Visualization

Here, We try two different comments and check whether they are toxic, severe toxic, obsene, or they are threatening, insult or and identity hate.

1.
![1](https://user-images.githubusercontent.com/49206555/103124213-05787900-46ad-11eb-9781-763db7d8daf4.PNG)


2. 
![2](https://user-images.githubusercontent.com/49206555/103124216-06a9a600-46ad-11eb-9637-494e58a34b5b.PNG)


## Packages Used
* Pandas
* Math
* SciPy
* Scikit Learn
* Numpy
* Joblib
